# -*- coding: utf-8 -*-
"""Dog_breed_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CLEv-2bwed1FU3zAvi_qnoG5RVclMg3I
"""

from google.colab import files
files.upload()

!pip install -q kaggle

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Colab Notebooks/Dog_Breed_prediction
!mkdir dog_dataset

# Commented out IPython magic to ensure Python compatibility.
# %cd dog_dataset

!kaggle datasets list -s dogbreedidfromcomp

!kaggle datasets download catherinehorng/dogbreedidfromcomp

# Commented out IPython magic to ensure Python compatibility.
# %cd ..

!unzip dog_dataset/dogbreedidfromcomp.zip -d dog_dataset
!rm dog_dataset/dogbreedidfromcomp.zip
!rm dog_dataset/sample_submission.csv

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm
from keras.preprocessing import image
from sklearn.preprocessing import label_binarize
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Flatten, Dense
from keras.optimizers import Adam

data  = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Dog_Breed_prediction/dog_dataset/labels.csv')
data.shape

breed_all = data['breed']
breed_counts = breed_all.value_counts()
breed_counts.head()

breed_counts

BREED_CLASS = ['scottish_deerhound','maltese_dog','bernese_mountain_dog']
data = data[data['breed'].isin(BREED_CLASS)]
data = data.reset_index()
data.shape

xdata = np.zeros((len(data), 224, 224, 3), dtype='float32')
ydata = label_binarize(data['breed'], classes=BREED_CLASS)
for i in tqdm(range(len(data))):
  img = image.load_img('/content/drive/MyDrive/Colab Notebooks/Dog_Breed_prediction/dog_dataset/train/%s.jpg' % data['id'][i], target_size = (224,224))
  img = image.img_to_array(img)
  x = np.expand_dims(img.copy(), axis=0)
  xdata[i] = x / 255.0

xdata.shape
xdata.size

model = Sequential()
model.add(Conv2D(filters=64, kernel_size=(5,5), activation='relu', input_shape=(224,224,3)))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Conv2D(filters = 32, kernel_size = (3,3), activation ='relu', kernel_regularizer = 'l2'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Conv2D(filters = 16, kernel_size = (7,7), activation ='relu', kernel_regularizer = 'l2'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Conv2D(filters = 8, kernel_size = (5,5), activation ='relu', kernel_regularizer = 'l2'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Flatten())
model.add(Dense(128, activation = "relu", kernel_regularizer = 'l2'))
model.add(Dense(64, activation = "relu", kernel_regularizer = 'l2'))
model.add(Dense(len(BREED_CLASS), activation = "softmax"))

model.compile(loss = 'categorical_crossentropy', optimizer = Adam(0.0001),metrics=['accuracy'])

model.summary()

xtrain_val, xtest, ytrain_val, ytest = train_test_split(xdata, ydata, test_size = 0.1)
xtrain, xval, ytrain, yval = train_test_split(xtrain_val, ytrain_val, test_size = 0.2)

epochs = 100
batch_size = 128

history = model.fit(xtrain, ytrain, batch_size = batch_size, epochs = epochs,
                    validation_data = (xval, yval))

# Plot the training history
plt.figure(figsize=(12, 5))
plt.plot(history.history['accuracy'], color='r')
plt.plot(history.history['val_accuracy'], color='b')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['train', 'val'])

plt.show()

Y_pred = model.predict(xtest)
score = model.evaluate(xtest, ytest)
print('Accuracy over the test set: \n ', round((score[1]*100), 2), '%')

# Plotting image to compare
plt.imshow(xtest[1,:,:,:])
plt.show()

# Finding max value from predition list and comaparing original value vs predicted
print("Originally : ",data['breed'][np.argmax(ytest[1])])
print("Predicted : ",data['breed'][np.argmax(Y_pred[1])])