# -*- coding: utf-8 -*-
"""Tesseract_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wq6JhbI1w4OxvbZUHfyDNhzou9d701qL
"""

import requests
r = requests.get("https://raw.githubusercontent.com/tesseract-ocr/tessdata/4.00/ind.traineddata", stream = True)
with open("/usr/share/tesseract-ocr/4.00/tessdata/ind.traineddata", "wb") as file:
    for block in r.iter_content(chunk_size = 1024):
         if block:
             file.write(block)

! apt install tesseract-ocr libtesseract-dev libmagickwand-dev

! pip install pytesseract wand opencv-python

from IPython.display import HTML
from PIL import Image
import pytesseract
import cv2
import numpy as np
import re

image = Image.open(requests.get('https://i.stack.imgur.com/pbIdS.png', stream=True).raw)
image.resize((300,150))
image.save('sample.png')
image

custom_config = r'l eng --oem 3 --psm 6'
text = pytesseract.image_to_string(image,config=custom_config)
print(text)

# Extracting text from image and removing irrelevant symbols from characters
try:
  text=pytesseract.image_to_string(image,lang="eng")
  characters_to_remove = "!()@—*“>+-/,'|£#%$&^_~"
  new_string = text
  for character in characters_to_remove:
    new_string = new_string.replace(character, "")
  print(new_string)
except IOError as e:
    print("Error (%s)." % e)

image = cv2.imread('sample.png')
def get_greyscale(image):
  return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
gray = get_greyscale(image)
Image.fromarray(gray)

def remove_noise(image):
  return cv2.medianBlur(image, 3)
blur = remove_noise(gray)
Image.fromarray(blur)

def thresholding(image):
  return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
thresh = thresholding(blur)
Image.fromarray(thresh)

def erosion(image):
  kernel = np.ones((5,5),np.uint8)
  return cv2.erode(image,kernel, iterations = 1)
eroded = erosion(gray)
Image.fromarray(eroded)

def opening(image):
  kernel = np.ones((5,5),np.uint8)
  return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)
opened = opening(thresh)
Image.fromarray(opened)

def canny(image):
    return cv2.Canny(image, 100, 200)
canny = canny(gray)
Image.fromarray(canny)

#skew correction
def deskew(image):
    coords = np.column_stack(np.where(image > 0))
    angle = cv2.minAreaRect(coords)[-1]
    if angle < -45:
        angle = -(90 + angle)
    else:
        angle = -angle
    (h, w) = image.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
    return rotated
rotated = deskew(gray)

Image.fromarray(rotated)

def match_template(image, template):
    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)
match = match_template(gray, gray)
match

# Drawing rectangle around text
img = cv2.imread('sample.png')
h, w, c = img.shape
boxes = pytesseract.image_to_boxes(img)
for b in boxes.splitlines():
    b = b.split(' ')
    img = cv2.rectangle(img, (int(b[1]), h - int(b[2])), (int(b[3]), h - int(b[4])), (0, 255, 0), 2)
Image.fromarray(img)

img = cv2.imread('sample.png')
d = pytesseract.image_to_data(img, output_type=pytesseract.Output.DICT)
print(d.keys())
keys = list(d.keys())

date_pattern = 'artificially'

n_boxes = len(d['text'])
for i in range(n_boxes):
    if int(d['conf'][i]) > 60:
    	if re.match(date_pattern, d['text'][i]):
	        (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])
	        img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)
Image.fromarray(img)